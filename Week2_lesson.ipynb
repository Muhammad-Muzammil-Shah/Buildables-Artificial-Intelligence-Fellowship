{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6da588",
   "metadata": {
    "id": "bf6da588"
   },
   "source": [
    "# **Buckle Up ! We are starting our week 2 roller coaster**\n",
    "\n",
    "In our first week we covered some theoritical concepts and completed our setup so its time we start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b55c5",
   "metadata": {
    "id": "ca6b55c5"
   },
   "source": [
    "## üìì**Conversational AI Concepts & Model Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7ace2",
   "metadata": {
    "id": "f1b7ace2"
   },
   "source": [
    "üéØ By the end of this week, you will:\n",
    "\n",
    "- Understand LLMs, STT, TTS models and their roles.\n",
    "\n",
    "- Know how to connect to LLMs with APIs (Groq as example).\n",
    "\n",
    "- Use Python (requests + JSON) for API interaction.\n",
    "\n",
    "- Start building a basic chatbot with memory and preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c5144",
   "metadata": {
    "id": "8e3c5144"
   },
   "source": [
    "---\n",
    "\n",
    "## üåü Large Language Models (LLMs) üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03968dc4",
   "metadata": {
    "id": "03968dc4"
   },
   "source": [
    "---\n",
    "\n",
    "### ‚ùó **Question 1**: What is an LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd894fc",
   "metadata": {
    "id": "9dd894fc"
   },
   "source": [
    "üëâ It‚Äôs like a super-smart text predictor that can read, understand, and generate human-like sentences.\n",
    "\n",
    "You give it some words ‚Üí it guesses the next words in a way that makes sense.\n",
    "\n",
    "For example:\n",
    "\n",
    "1) You ask a question ‚Üí it gives you an answer.\n",
    "\n",
    "2) You write a sentence ‚Üí it can complete it.\n",
    "\n",
    "3) You give it a topic ‚Üí it can write an essay, code, or even a story.\n",
    "\n",
    "So, its a type of AI trained on huge amounts of text data to generate or understand text.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77076ddc",
   "metadata": {
    "id": "77076ddc"
   },
   "source": [
    "### Types of LLMs\n",
    "\n",
    "1. Encoder-only models (e.g., BERT)\n",
    "\n",
    "    - Best for understanding text (classification, sentiment analysis, embeddings).\n",
    "\n",
    "    - ‚ùå Not good at generating text.\n",
    "\n",
    "2. Decoder-only models (e.g., GPT, LLaMA, Mistral)\n",
    "\n",
    "    - Best for text generation (chatbots, writing, summarization).\n",
    "\n",
    "    - What we use in chatbots.\n",
    "\n",
    "3. Encoder-decoder models (e.g., T5, BART)\n",
    "\n",
    "    - Good at transforming text (translation, summarization, Q&A)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339099fe",
   "metadata": {
    "id": "339099fe"
   },
   "source": [
    "### Must-Knows about LLMs\n",
    "\n",
    "- They don‚Äôt ‚Äúthink‚Äù like humans ‚Üí They predict text based on training.\n",
    "\n",
    "- Garbage in ‚Üí garbage out: Poor prompts = poor answers.\n",
    "\n",
    "- Token limits: Models can only ‚Äúsee‚Äù a certain number of words at a time.\n",
    "\n",
    "- Biases: Trained on internet text ‚Üí may reflect biases/errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b2dd4",
   "metadata": {
    "id": "8b1b2dd4"
   },
   "source": [
    "### üí° **Quick Questions**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753565a",
   "metadata": {
    "id": "7753565a"
   },
   "source": [
    "1. Why might a chatbot built on BERT (encoder-only) struggle to answer open-ended questions?\n",
    "\n",
    "- Answer üëâ BERT is designed mainly for understanding and classifying text, not generating it. It cannot produce long, creative, or open-ended responses because it lacks a decoder to generate new text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5feffca",
   "metadata": {
    "id": "a5feffca"
   },
   "source": [
    "---\n",
    "\n",
    "## üåü Speech-to-Text (STT) üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393abf7",
   "metadata": {
    "id": "9393abf7"
   },
   "source": [
    "---\n",
    "\n",
    "### ‚ùó **Question 2**: What is STT?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f54ac00",
   "metadata": {
    "id": "3f54ac00"
   },
   "source": [
    "üëâ listens to your voice and turns it into written text.\n",
    "\n",
    "- Converts **audio ‚Üí text**.\n",
    "- Enables voice input for conversational AI.\n",
    "- Think of it as the **ears** of the chatbot.\n",
    "\n",
    "**Popular STT Models**:\n",
    "\n",
    "1) **Whisper (OpenAI)** ‚Äì strong at multilingual speech recognition.\n",
    "2) **Google Speech-to-Text API** ‚Äì widely used, real-time transcription.\n",
    "3) **Vosk** ‚Äì lightweight, offline speech recognition.\n",
    "\n",
    "**Common Usages**\n",
    "\n",
    "1) Voice assistants (Alexa, Siri, Google Assistant).\n",
    "2) Automated captions in meetings or lectures.\n",
    "3) Voice-enabled customer support.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99714c",
   "metadata": {
    "id": "cc99714c"
   },
   "source": [
    "### Must-Knows about STT\n",
    "\n",
    "- Accuracy depends on **noise, accents, clarity of speech**.\n",
    "\n",
    "- Some models need **internet connection** (API-based), others run **offline**.\n",
    "\n",
    "- Preprocessing audio (noise reduction) improves results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec23bf9a",
   "metadata": {
    "id": "ec23bf9a"
   },
   "source": [
    "### üí° **Quick Questions**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407d8a82",
   "metadata": {
    "id": "407d8a82"
   },
   "source": [
    "2. Why do you think meeting transcription apps like Zoom or Google Meet struggle when multiple people talk at once?\n",
    "\n",
    "- Answer üëâ These apps struggle because overlapping voices make it hard for the model to separate and recognize each speaker‚Äôs words. Background noise and different accents can also reduce accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2959a81",
   "metadata": {
    "id": "f2959a81"
   },
   "source": [
    "---\n",
    "\n",
    "## üåü Text-to-Speech (TTS) üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6650b62d",
   "metadata": {
    "id": "6650b62d"
   },
   "source": [
    "---\n",
    "\n",
    "### ‚ùó **Question 3**: What is TTS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17df418",
   "metadata": {
    "id": "e17df418"
   },
   "source": [
    "üëâ takes written text and speaks it out loud in a human-like voice.\n",
    "\n",
    "- Converts **text ‚Üí audio (speech)**.\n",
    "- Think of it as the **mouth** of the chatbot.\n",
    "- Makes AI ‚Äúspeak‚Äù naturally.\n",
    "\n",
    "**Popular TTS Models**:\n",
    "\n",
    "1) **Google TTS** ‚Äì supports many languages and voices.\n",
    "2) **Amazon Polly** ‚Äì lifelike voice synthesis with customization.\n",
    "3) **ElevenLabs** ‚Äì cutting-edge, realistic voice cloning.\n",
    "\n",
    "**Common Usages**\n",
    "\n",
    "1) Screen readers for visually impaired users.\n",
    "2) AI chatbots with voice output.\n",
    "3) Audiobooks or podcast generation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb2471",
   "metadata": {
    "id": "cfdb2471"
   },
   "source": [
    "### Must-Knows about TTS\n",
    "\n",
    "- Some voices sound robotic; others use **neural TTS** for natural tones.\n",
    "\n",
    "- Latency matters ‚Üí If too slow, conversation feels unnatural.\n",
    "\n",
    "- Some TTS services allow **custom voices**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49cb51",
   "metadata": {
    "id": "ee49cb51"
   },
   "source": [
    "### üí° **Quick Questions**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f3eb2",
   "metadata": {
    "id": "ee8f3eb2"
   },
   "source": [
    "3. If you were designing a voice-based AI tutor, what qualities would you want in its TTS voice (tone, speed, clarity, etc.)?\n",
    "\n",
    "- Answer üëâ I would want the TTS voice to be clear, friendly, and natural-sounding. The tone should be encouraging and patient, the speed should be moderate and adjustable, and the pronunciation should be accurate to help learners understand easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8042c582",
   "metadata": {
    "id": "8042c582"
   },
   "source": [
    "---\n",
    "\n",
    "## üåü Using APIs for LLMs with Groq üåü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7889d8ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7889d8ee",
    "outputId": "41256f11-8d91-4bf2-d9f7-dae1cfd09f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational AI, also known as conversational interfaces or chatbots, is a type of artificial intelligence (AI) that allows computers to engage in natural-sounding conversations with humans. It enables users to interact with systems, applications, or services through text or voice, just like they would with another human being.\n",
      "\n",
      "Conversational AI uses various techniques, such as:\n",
      "\n",
      "1. **Natural Language Processing (NLP)**: This involves analyzing and understanding human language, including syntax, semantics, and pragmatics.\n",
      "2. **Machine Learning**: This enables the system to learn from user interactions and improve its responses over time.\n",
      "3. **Dialogue Management**: This involves managing the conversation flow, including recognizing user inputs, generating responses, and determining when to ask follow-up questions.\n",
      "\n",
      "Conversational AI has many applications, such as:\n",
      "\n",
      "1. **Customer service bots**: These help customers with inquiries, complaints, or support requests, 24/7.\n",
      "2. **Virtual assistants**: These, like Siri, Alexa, or Google Assistant, can perform various tasks, such as setting reminders, sending messages, or controlling smart home devices.\n",
      "3. **Chatbots**: These are used in e-commerce, healthcare, finance, and other industries to provide information, answer questions, or guide users through complex processes.\n",
      "4. **Language translation**: Conversational AI can translate languages in real-time, facilitating global communication.\n",
      "\n",
      "The benefits of conversational AI include:\n",
      "\n",
      "1. **Improved user experience**: Users can interact with systems in a more natural and intuitive way.\n",
      "2. **Increased efficiency**: Automated customer service and other tasks can save time and resources.\n",
      "3. **Enhanced accessibility**: Conversational AI can reach a broader audience, including those with disabilities or language barriers.\n",
      "\n",
      "However, conversational AI also raises concerns about:\n",
      "\n",
      "1. **Job displacement**: Automation could replace human customer support agents and other roles.\n",
      "2. **Data security**: AI systems can collect and process vast amounts of user data, which must be protected.\n",
      "3. **Bias and misinterpretation**: AI systems can perpetuate biases and misunderstand user intent, leading to errors or unintended consequences.\n",
      "\n",
      "Overall, conversational AI has the potential to greatly enhance human-computer interaction and improve various aspects of our lives.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"API key\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello! What is conversational AI?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c20eb",
   "metadata": {
    "id": "a56c20eb"
   },
   "source": [
    "---\n",
    "\n",
    "## üåü Assignments üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc2ce6",
   "metadata": {
    "id": "2bcc2ce6"
   },
   "source": [
    "### üìù Assignment 1: LLM Understanding\n",
    "\n",
    "* Write a short note (3‚Äì4 sentences) explaining the difference between **encoder-only, decoder-only, and encoder-decoder LLMs**.\n",
    "* Give one example usage of each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48d225b",
   "metadata": {
    "id": "b48d225b"
   },
   "source": [
    "Encoder-only LLMs, like BERT, are designed mainly for understanding and\n",
    "analyzing text by creating contextual embeddings; they excel at tasks\n",
    "such as classification and sentiment analysis but cannot generate new text.\n",
    "Decoder-only LLMs, such as GPT, focus on generating text by predicting\n",
    "the next word in a sequence, making them ideal for chatbots and creative\n",
    "writing. Encoder-decoder LLMs, like T5 or BART, combine both architectures\n",
    "to transform input text into output text, which is useful for tasks like\n",
    "translation and summarization.\n",
    "\n",
    "**Examples:**  \n",
    "- Encoder-only: Sentiment analysis (BERT)  \n",
    "- Decoder-only: Conversational chatbot (GPT)  \n",
    "- Encoder-decoder: Machine translation (T5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370084b8",
   "metadata": {
    "id": "370084b8"
   },
   "source": [
    "### üìù Assignment 2: STT/TTS Exploration\n",
    "\n",
    "* Find **one STT model** and **one TTS model** (other than Whisper/Google).\n",
    "* Write down:\n",
    "\n",
    "  * What it does.\n",
    "  * One possible application.\n",
    "\n",
    "**STT Model: Vosk**  \n",
    "- What it does: Vosk listens to your voice and turns it into written words.  \n",
    "- One possible application: It can be used in offline voice typing apps, so you can talk and your words appear as text even without internet.\n",
    "\n",
    "**TTS Model: Amazon Polly**  \n",
    "- What it does: Amazon Polly takes written text and reads it out loud in a human-like voice.  \n",
    "- One possible application: It can be used to make talking books for people who have trouble reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84824b65",
   "metadata": {
    "id": "84824b65"
   },
   "source": [
    "### üìù Assignment 3: Build a Chatbot with Memory\n",
    "\n",
    "* Write a Python program that:\n",
    "\n",
    "  * Takes user input in a loop.\n",
    "  * Sends it to Groq API.\n",
    "  * Stores the last 5 messages in memory.\n",
    "  * Ends when user types `\"quit\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506cdc81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "506cdc81",
    "outputId": "5a7d5628-7fd8-435f-ac75-e103ca8393c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hi\n",
      "Chatbot: Hello. Is there something I can help you with?\n",
      "You: how are you\n",
      "Chatbot: I'm just a computer program, so I don't have feelings in the same way that humans do, but I'm functioning properly and ready to help with any questions or tasks you may have. How about you? How's your day going?\n",
      "You: what are you doing\n",
      "Chatbot: I'm a large language model, so my primary function is to process and respond to text-based input. Here are some ways I'm currently \"doing things\":\n",
      "\n",
      "1. **Listening**: I'm waiting for your next message, and I'll respond based on what you type.\n",
      "2. **Learning**: In the background, I'm continuously learning from the vast amount of text data I was trained on, which helps me improve my language understanding and generation capabilities.\n",
      "3. **Generating text**: When you ask me a question or request information, I'm generating text that's relevant and accurate based on my training data.\n",
      "4. **Improving**: My developers are constantly working on updating and refining my model to make me more helpful, accurate, and engaging.\n",
      "\n",
      "These tasks happen in a seamless and automatic way, so you can interact with me without worrying about the technical details.\n",
      "You: ok\n",
      "Chatbot: It seems like you're ready to move on or have something specific in mind. Go ahead and ask me a question, share an idea, or start a conversation - I'm all ears (or rather, all text). What's next?\n",
      "You: quit\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"API Key\")\n",
    "\n",
    "messages = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    messages = messages[-2:]\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=messages\n",
    "    )\n",
    "    bot_reply = response.choices[0].message.content\n",
    "    print(\"Chatbot:\", bot_reply)\n",
    "    messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "    messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef3132",
   "metadata": {
    "id": "1aef3132"
   },
   "source": [
    "### üìù Assignment 4: Preprocessing Function\n",
    "\n",
    "* Write a function to clean user input:\n",
    "\n",
    "  * Lowercase text.\n",
    "  * Remove punctuation.\n",
    "  * Strip extra spaces.\n",
    "\n",
    "Test with: `\"  HELLo!!!  How ARE you?? \"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad9f1c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dad9f1c5",
    "outputId": "caf4a125-b89e-48e2-a952-14d7862b1f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are you\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "test_input = \"  HELLo!!!  How ARE you?? \"\n",
    "print(clean_text(test_input))  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53027998",
   "metadata": {
    "id": "53027998"
   },
   "source": [
    "### üìù Assignment 5: Text Preprocessing\n",
    "\n",
    "* Write a function that:\n",
    "\n",
    "    * Converts text to lowercase.\n",
    "    * Removes punctuation & numbers.\n",
    "    * Removes stopwords (`the, is, and...`).\n",
    "    * Applies stemming or lemmatization.\n",
    "    * Removes words shorter than 3 characters.\n",
    "    * Keeps only nouns, verbs, and adjectives (using POS tagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2090c091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2090c091",
    "outputId": "0d23abc7-0725-4051-ec0c-c6ece05e3cc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The quick brown foxes were jumping over the lazy dogs in 2025!\n",
      "Processed: ['quick', 'brown', 'fox', 'jumping', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger_eng')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    words = [w for w in words if len(w) >= 3]\n",
    "    tagged_words = pos_tag(words)\n",
    "    allowed_tags = {\"NN\", \"NNS\", \"NNP\", \"NNPS\",\n",
    "                    \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\",\n",
    "                    \"JJ\", \"JJR\", \"JJS\"}\n",
    "\n",
    "    filtered_words = [word for word, tag in tagged_words if tag in allowed_tags]\n",
    "\n",
    "    return filtered_words\n",
    "sample_text = \"The quick brown foxes were jumping over the lazy dogs in 2025!\"\n",
    "print(\"Original:\", sample_text)\n",
    "print(\"Processed:\", preprocess_text(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r7otR7FbWzch",
   "metadata": {
    "id": "r7otR7FbWzch"
   },
   "source": [
    "**Chatbot with Text Preprocessing**\n",
    "\n",
    "This code integrates a Groq-powered chatbot using the LLaMA 3.1 model while applying advanced NLP preprocessing. The preprocess_text function cleans, tokenizes, lemmatizes, removes stopwords, and filters words by POS tags. The processed output ensures meaningful context extraction from chatbot responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "yv0NS4VvRHvl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yv0NS4VvRHvl",
    "outputId": "d2eacb3b-40dd-4cda-c18e-e7ea490b839d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: It seems like you meant to type \"hello\". How can I assist you today?\n",
      "Processed: ['seems', 'meant', 'type', 'hello', 'assist', 'today']\n",
      "You: hi\n",
      "Original: It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "Processed: ['nice', 'meet', 'something', 'help', 'like', 'chat']\n",
      "You: how are you\n",
      "Original: I'm just a computer program, so I don't have feelings or emotions like humans do. I'm functioning properly and ready to help answer any questions or provide information you might need. What about you? How's your day going?\n",
      "Processed: ['computer', 'program', 'dont', 'feeling', 'emotion', 'human', 'functioning', 'ready', 'help', 'answer', 'question', 'information', 'need', 'hows', 'day', 'going']\n",
      "You: good one\n",
      "Original: I guess I could have done better than reiterating the obvious. What's on your mind? Want to talk about something specific or just chat about a topic?\n",
      "Processed: ['guess', 'done', 'reiterating', 'obvious', 'whats', 'mind', 'want', 'talk', 'something', 'specific', 'topic']\n",
      "You: haha\n",
      "Original: I think I managed to start with a bit of internet slang. So, how's your day going so far?\n",
      "Processed: ['think', 'managed', 'start', 'bit', 'internet', 'slang', 'hows', 'day', 'going']\n",
      "You: can yoe guide me\n",
      "Original: I'd be happy to guide you through any topics or questions you may have.\n",
      "\n",
      "What would you like to learn about or discuss today? Is it related to a specific subject, like science, history, or technology? Or do you have a more general question?\n",
      "Processed: ['happy', 'guide', 'question', 'like', 'learn', 'discus', 'today', 'related', 'specific', 'subject', 'science', 'history', 'technology', 'general', 'question']\n",
      "You: quit\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    words = [w for w in words if len(w) >= 3]\n",
    "    tagged_words = pos_tag(words)\n",
    "    allowed_tags = {\"NN\", \"NNS\", \"NNP\", \"NNPS\",\n",
    "                    \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\",\n",
    "                    \"JJ\", \"JJR\", \"JJS\"}\n",
    "\n",
    "    filtered_words = [word for word, tag in tagged_words if tag in allowed_tags]\n",
    "\n",
    "    return filtered_words\n",
    "sample_text = bot_reply\n",
    "print(\"Original:\", sample_text)\n",
    "print(\"Processed:\", preprocess_text(sample_text))\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"apikye\")\n",
    "\n",
    "messages = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    messages = messages[-2:]\n",
    "\n",
    "    # Send to Groq API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=messages\n",
    "    )\n",
    "    bot_reply = response.choices[0].message.content\n",
    "    sample_text = bot_reply\n",
    "    print(\"Original:\", sample_text)\n",
    "    print(\"Processed:\", preprocess_text(sample_text))\n",
    "    def preprocess_text(text):\n",
    "\n",
    "      text = text.lower()\n",
    "      text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "      words = word_tokenize(text)\n",
    "      stop_words = set(stopwords.words(\"english\"))\n",
    "      words = [w for w in words if w not in stop_words]\n",
    "      lemmatizer = WordNetLemmatizer()\n",
    "      words = [lemmatizer.lemmatize(w) for w in words]\n",
    "      words = [w for w in words if len(w) >= 3]\n",
    "      tagged_words = pos_tag(words)\n",
    "      allowed_tags = {\"NN\", \"NNS\", \"NNP\", \"NNPS\",\n",
    "                    \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\",\n",
    "                    \"JJ\", \"JJR\", \"JJS\"}\n",
    "\n",
    "      filtered_words = [word for word, tag in tagged_words if tag in allowed_tags]\n",
    "\n",
    "      return filtered_words\n",
    "\n",
    "\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
    "    messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68c035",
   "metadata": {
    "id": "bb68c035"
   },
   "source": [
    "### üìù Assignment 6: Reflection\n",
    "\n",
    "* Answer in 2‚Äì3 sentences:\n",
    "\n",
    "    * Why is context memory important in chatbots?\n",
    "    * Why should beginners always check **API limits and pricing**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da7983",
   "metadata": {
    "id": "d9da7983"
   },
   "source": [
    "Context memory is important in chatbots because it helps the bot remember previous messages, making conversations feel more natural and allowing it to give relevant, accurate responses. Beginners should always check API limits and pricing to avoid unexpected costs and ensure their project does not stop working due to hitting usage limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b787de4",
   "metadata": {
    "id": "4b787de4"
   },
   "source": [
    "---\n",
    "\n",
    "### **Hints:**\n",
    "\n",
    "1) Stemming:\n",
    "    - Cuts off word endings to get the ‚Äúroot.‚Äù\n",
    "    - Very mechanical ‚Üí may produce non-real words.\n",
    "    - Example:\n",
    "        - \"studies\" ‚Üí \"studi\"\n",
    "        - \"running\" ‚Üí \"run\"\n",
    "\n",
    "2) Lemmatization:\n",
    "    - Smarter ‚Üí uses vocabulary + grammar rules.\n",
    "    - Always gives a real word (the **lemma**).\n",
    "    - Example:\n",
    "        - \"studies\" ‚Üí \"study\"\n",
    "        - \"running\" ‚Üí \"run\"\n",
    "\n",
    "3) Part-of-Speech (POS) tagging means labeling each word in a sentence with its grammatical role ‚Äî like **noun, verb, adjective, adverb, pronoun, etc.**\n",
    "\n",
    "    - Example:\n",
    "        - Sentence ‚Üí *‚ÄúThe cat is sleeping on the mat.‚Äù*\n",
    "\n",
    "    - POS tags ‚Üí\n",
    "        - The ‚Üí Determiner (DT)\n",
    "        - cat ‚Üí Noun (NN)\n",
    "        - is ‚Üí Verb (VBZ)\n",
    "        - sleeping ‚Üí Verb (VBG)\n",
    "        - on ‚Üí Preposition (IN)\n",
    "        - the ‚Üí Determiner (DT)\n",
    "        - mat ‚Üí Noun (NN)\n",
    "\n",
    "    - **In short:** POS tagging helps machines understand **how words function in a sentence**, which is useful in NLP tasks like machine translation, text classification, and question answering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec98bb",
   "metadata": {
    "id": "3cec98bb"
   },
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Recap\n",
    "\n",
    "This week you learned:\n",
    "\n",
    "* **LLMs**: Types, uses, must-knows.\n",
    "* **STT & TTS**: How they connect with LLMs.\n",
    "* **APIs**: Connecting to LLMs with Groq.\n",
    "* Built your first chatbot foundation."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
